{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKU4IGW3HdqZ"
      },
      "outputs": [],
      "source": [
        "#use it cell only when you use google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyO4KYwJAwGe"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5K4Mxf4AwGg"
      },
      "outputs": [],
      "source": [
        "def preprocess_socialmediacomments(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    text = re.sub('[\\W]+', ' ', text.lower())\n",
        "    text = text+' '.join(emoticons).replace('-', '') \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYcgnHwrAwGg"
      },
      "outputs": [],
      "source": [
        "tqdm.pandas()\n",
        "#put on your csv file\n",
        "df = pd.read_csv('')\n",
        "df['Comment'] = df['Comment'].progress_apply(preprocess_socialmediacomments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD7lFLgLAwGh"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV0ppvDLAwGh"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d60Sy_n1IzUO"
      },
      "outputs": [],
      "source": [
        "[w for w in tokenizer_porter('সত্যি গানটা অসাধারণ লেগেছে') if w not in stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT-Yve2fAwGh"
      },
      "outputs": [],
      "source": [
        "[w for w in tokenizer_porter('a runner likes running and runs a lot') if w not in stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ8LbrrDAwGi"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\(|D|P)',text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower())\n",
        "    text += ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in tokenizer_porter(text) if w not in stop]\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv81ZeqzAwGi"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "vect = HashingVectorizer(decode_error='ignore', n_features=2**21,preprocessor=None,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByDbdv1LAwGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss='log', random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-EC8kV2AwGj"
      },
      "outputs": [],
      "source": [
        "X = df[\"Comment\"].to_list()\n",
        "y = df['Harmful']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvs4QIOqAwGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "017laY4TAwGj"
      },
      "outputs": [],
      "source": [
        "X_train = vect.transform(X_train)\n",
        "X_test = vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8iLMfhTAwGk"
      },
      "outputs": [],
      "source": [
        "classes = np.array([0, 1])\n",
        "clf.partial_fit(X_train, y_train,classes=classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoblZ1voAwGk"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRT1fPb0AwGk"
      },
      "outputs": [],
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivpcav1uQsdp"
      },
      "outputs": [],
      "source": [
        "label = {0:'ক্ষতিকর না', 1:'ক্ষতিকর'}\n",
        "example = [\"একটু হিসাব করে দেখেন, আর্জেন্টিনার জনসংখ্যা ৪ কোটি... আর আমাদের ১৬ কোটির দেশে প্রায় অর্ধেকই  (৮ কোটি) হলো আর্জেন্টিনার সাপোর্টার\"]\n",
        "X = vect.transform(example)\n",
        "print('Prediction: %s\\nProbability: %.2f%%'\n",
        "%(label[clf.predict(X)[0]],np.max(clf.predict_proba(X))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RpeM-XrAwGl"
      },
      "outputs": [],
      "source": [
        "label = {0:'Good', 1:'Harmful'}\n",
        "example = [\"Go to Hell. Fuck you\"]\n",
        "X = vect.transform(example)\n",
        "print('Prediction: %s\\nProbability: %.2f%%'\n",
        "%(label[clf.predict(X)[0]],np.max(clf.predict_proba(X))*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit",
      "language": "python",
      "name": "python37764bit24e04fb98b5343e5a5f328fddbd4640d"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
